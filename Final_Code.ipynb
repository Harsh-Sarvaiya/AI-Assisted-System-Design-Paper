{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aw8JgVgQaFyCPHiLiw51IhxTHhbjq7eW",
      "authorship_tag": "ABX9TyO6ntz5Pkr/t1NhMOfLV2kF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-Sarvaiya/AI-Assisted-System-Design-Paper/blob/main/Final_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plantuml\n",
        "!pip install python-docx\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "ZM2g78JAv4qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba944dd-0463-42ab-ed18-043a6b185a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
     
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q6il7RcvCQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "0acc2f58-69b1-44e7-f527-f9924534c550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cdadc07d-a11a-48cd-9543-02a3584e8666\", \"use_case_scenarios.docx\", 49205)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2107a57b-cb47-4778-af92-373d2b8a52b6\", \"plantuml_sequence_diagrams.docx\", 47665)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b5a3d750-d260-4d64-b31b-a4917cae4f4a\", \"plantuml_sequences.zip\", 757887)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Optional: Install PlantUML if you plan to generate images\n",
        "# !pip install plantuml\n",
        "\n",
        "from plantuml import PlantUML\n",
        "\n",
        "# Load user stories from CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Research with Professor - GPT to SD/Papers and data/Selected_User_Stories.csv\")\n",
        "user_stories = df[\"Random Line\"].tolist()\n",
        "\n",
        "# Define OpenAI API key securely\n",
        "openai.api_key = \"API_KEY\"  # Recommended to set as an environment variable\n",
        "\n",
        "# Function to get use case scenarios in UML format with additional details\n",
        "def get_use_case_scenarios_in_uml(user_story):\n",
        "    \"\"\"\n",
        "    Uses OpenAI API to generate detailed use case scenarios in UML format for a user story.\n",
        "    Includes main flow, alternate flow, triggers, actors, preconditions, and postconditions.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in UML use case design. For the following user story, generate a complete UML use case scenario with detailed sections:\n",
        "    - Use Case Name: A short descriptive name for the use case.\n",
        "    - Actors: List all actors involved.\n",
        "    - Preconditions: Any conditions that must be met before the use case starts.\n",
        "    - Triggers: The events or conditions that start the use case.\n",
        "    - Main Flow of Events: A step-by-step description of the primary flow.\n",
        "    - Alternate Flow of Events: Any alternate or exception flows.\n",
        "    - Postconditions: The final state after the use case completes.\n",
        "\n",
        "    User Story: \"{user_story}\"\n",
        "\n",
        "    Ensure the output is complete and does not contain placeholders such as \"### Use Case Name\".\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert in UML use case design and software engineering.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=2000,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        response_text = response['choices'][0]['message']['content'].strip()\n",
        "        if \"### Use Case Name\" in response_text or not response_text:\n",
        "            response_text = \"Error: Unable to generate detailed use case scenario.\"\n",
        "        return response_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error for story: {user_story} - {e}\")\n",
        "        return \"Error: Unable to generate use case scenario\"\n",
        "\n",
        "# Function to convert use case scenario to PlantUML sequence diagram script\n",
        "def get_plantuml_sequence_diagram(use_case_scenario):\n",
        "    \"\"\"\n",
        "    Uses OpenAI API to generate a PlantUML sequence diagram script based on the use case scenario.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in software engineering and UML diagramming. Based on the following UML use case scenario, generate a PlantUML script for a sequence diagram that visualizes the main flow of events.\n",
        "\n",
        "    Use Case Scenario:\n",
        "    {use_case_scenario}\n",
        "\n",
        "    The PlantUML script should include all relevant actors and system components involved in the main flow.\n",
        "    Ensure the script is syntactically correct and can be rendered without errors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert in software engineering and UML diagramming.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=1500,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        plantuml_script = response['choices'][0]['message']['content'].strip()\n",
        "        if \"Error\" in plantuml_script or not plantuml_script:\n",
        "            plantuml_script = \"@startuml\\n' Error: Unable to generate sequence diagram\\n@enduml\"\n",
        "        return plantuml_script\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PlantUML script - {e}\")\n",
        "        return \"@startuml\\n' Error: Unable to generate sequence diagram\\n@enduml\"\n",
        "\n",
        "# Directory to save PlantUML scripts and diagrams\n",
        "plantuml_dir = \"plantuml_sequences\"\n",
        "os.makedirs(plantuml_dir, exist_ok=True)\n",
        "\n",
        "# Initialize PlantUML server (optional, if you have a local PlantUML server)\n",
        "# If you don't have a local server, you can use the default PlantUML public server\n",
        "plantuml_server = PlantUML(url='http://www.plantuml.com/plantuml/img/')  # Public server\n",
        "\n",
        "# Generate use case scenarios and corresponding PlantUML sequence diagrams\n",
        "use_case_results = []\n",
        "plantuml_scripts = []\n",
        "sequence_diagrams = []\n",
        "\n",
        "for idx, story in enumerate(user_stories, start=1):\n",
        "    print(f\"Processing User Story {idx}/{len(user_stories)}\")\n",
        "    use_case = get_use_case_scenarios_in_uml(story)\n",
        "    use_case_results.append((story, use_case))\n",
        "\n",
        "    # Generate PlantUML script\n",
        "    plantuml_script = get_plantuml_sequence_diagram(use_case)\n",
        "    plantuml_scripts.append((story, plantuml_script))\n",
        "\n",
        "    # Save PlantUML script to a file\n",
        "    sanitized_story = \"\".join([c if c.isalnum() or c in (' ', '_') else '_' for c in story])[:50]\n",
        "    puml_filename = f\"{plantuml_dir}/sequence_{idx}_{sanitized_story}.puml\"\n",
        "    with open(puml_filename, 'w') as f:\n",
        "        f.write(plantuml_script)\n",
        "\n",
        "    # Optionally, generate and save the sequence diagram image\n",
        "    try:\n",
        "        # Using PlantUML public server to generate the image\n",
        "        diagram_url = plantuml_server.get_url(plantuml_script)\n",
        "        diagram_filename = f\"{plantuml_dir}/sequence_{idx}_{sanitized_story}.png\"\n",
        "        # Download the image\n",
        "        import requests\n",
        "        img_data = requests.get(diagram_url).content\n",
        "        with open(diagram_filename, 'wb') as img_file:\n",
        "            img_file.write(img_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating diagram for story {idx}: {e}\")\n",
        "\n",
        "    time.sleep(1)  # Add delay to avoid rate limits\n",
        "\n",
        "# Save use case scenarios to a Word document\n",
        "doc = Document()\n",
        "doc.add_heading('UML Use Case Scenarios', level=1)\n",
        "\n",
        "for story, use_case in use_case_results:\n",
        "    doc.add_heading(f\"User Story: {story}\", level=2)\n",
        "    doc.add_paragraph(use_case)\n",
        "    doc.add_paragraph(\"\\n\")  # Add a blank line between entries\n",
        "\n",
        "doc.save(\"use_case_scenarios.docx\")\n",
        "\n",
        "# Save PlantUML scripts to a separate Word document (optional)\n",
        "puml_doc = Document()\n",
        "puml_doc.add_heading('PlantUML Sequence Diagrams', level=1)\n",
        "\n",
        "for story, script in plantuml_scripts:\n",
        "    puml_doc.add_heading(f\"User Story: {story}\", level=2)\n",
        "    puml_doc.add_paragraph(script)\n",
        "    puml_doc.add_paragraph(\"\\n\")  # Add a blank line between entries\n",
        "\n",
        "puml_doc.save(\"plantuml_sequence_diagrams.docx\")\n",
        "\n",
        "# Notify the user\n",
        "print(\"Word documents saved as 'use_case_scenarios.docx' and 'plantuml_sequence_diagrams.docx'.\")\n",
        "print(f\"PlantUML scripts and sequence diagram images are saved in the '{plantuml_dir}' directory.\")\n",
        "\n",
        "# Download the Word files in Google Colab (if applicable)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('use_case_scenarios.docx')\n",
        "    files.download('plantuml_sequence_diagrams.docx')\n",
        "    # Optionally, zip the PlantUML directory and download\n",
        "    import shutil\n",
        "    shutil.make_archive(\"plantuml_sequences\", 'zip', plantuml_dir)\n",
        "    files.download(\"plantuml_sequences.zip\")\n",
        "except ImportError:\n",
        "    print(\"Google Colab is not being used, files saved locally.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Optional: Install PlantUML if you plan to generate images\n",
        "# !pip install plantuml\n",
        "\n",
        "from plantuml import PlantUML\n",
        "\n",
        "# Load user stories from CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Research with Professor - GPT to SD/Papers and data/Selected_User_Stories.csv\")\n",
        "user_stories = df[\"Random Line\"].tolist()\n",
        "\n",
        "# Define OpenAI API key securely\n",
        "openai.api_key = \"API-KEY\"  # Recommended to set as an environment variable\n",
        "\n",
        "# # Function to get use case scenarios in UML format with additional details\n",
        "# def get_use_case_scenarios_in_uml(user_story):\n",
        "#     \"\"\"\n",
        "#     Uses OpenAI API to generate detailed use case scenarios in UML format for a user story.\n",
        "#     Includes main flow, alternate flow, triggers, actors, preconditions, and postconditions.\n",
        "#     \"\"\"\n",
        "#     prompt = f\"\"\"\n",
        "#     You are an expert in UML use case design. For the following user story, generate a complete UML use case scenario with detailed sections:\n",
        "#     - Use Case Name: A short descriptive name for the use case.\n",
        "#     - Actors: List all actors involved.\n",
        "#     - Preconditions: Any conditions that must be met before the use case starts.\n",
        "#     - Triggers: The events or conditions that start the use case.\n",
        "#     - Main Flow of Events: A step-by-step description of the primary flow.\n",
        "#     - Alternate Flow of Events: Any alternate or exception flows.\n",
        "#     - Postconditions: The final state after the use case completes.\n",
        "\n",
        "#     User Story: \"{user_story}\"\n",
        "\n",
        "#     Ensure the output is complete and does not contain placeholders such as \"### Use Case Name\".\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         response = openai.ChatCompletion.create(\n",
        "#             model=\"gpt-4\",\n",
        "#             messages=[\n",
        "#                 {\"role\": \"system\", \"content\": \"You are an expert in UML use case design and software engineering.\"},\n",
        "#                 {\"role\": \"user\", \"content\": prompt}\n",
        "#             ],\n",
        "#             max_tokens=2000,\n",
        "#             temperature=0.3\n",
        "#         )\n",
        "#         response_text = response['choices'][0]['message']['content'].strip()\n",
        "#         if \"### Use Case Name\" in response_text or not response_text:\n",
        "#             response_text = \"Error: Unable to generate detailed use case scenario.\"\n",
        "#         return response_text\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error for story: {user_story} - {e}\")\n",
        "#         return \"Error: Unable to generate use case scenario\"\n",
        "\n",
        "# Function to convert use case scenario to PlantUML sequence diagram script\n",
        "def get_plantuml_sequence_diagram(user_story):\n",
        "    \"\"\"\n",
        "    Uses OpenAI API to generate a PlantUML sequence diagram script based on the user story.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in software engineering and UML diagramming. Based on the following UML user story, generate a PlantUML script for a sequence diagram that visualizes the main flow of events. Only answer with the script.\n",
        "\n",
        "    Use Case Scenario: \"{user_story}\"\n",
        "\n",
        "    The PlantUML script should include all relevant actors and system components involved in the main flow.\n",
        "    Ensure the script is syntactically correct and can be rendered without errors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert in software engineering and UML diagramming.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=1500,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        plantuml_script = response['choices'][0]['message']['content'].strip()\n",
        "        if \"Error\" in plantuml_script or not plantuml_script:\n",
        "            plantuml_script = \"@startuml\\n' Error: Unable to generate sequence diagram\\n@enduml\"\n",
        "        return plantuml_script\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PlantUML script - {e}\")\n",
        "        return \"@startuml\\n' Error: Unable to generate sequence diagram\\n@enduml\"\n",
        "\n",
        "# Directory to save PlantUML scripts and diagrams\n",
        "plantuml_dir = \"plantuml_sequences\"\n",
        "os.makedirs(plantuml_dir, exist_ok=True)\n",
        "\n",
        "# Initialize PlantUML server (optional, if you have a local PlantUML server)\n",
        "# If you don't have a local server, you can use the default PlantUML public server\n",
        "plantuml_server = PlantUML(url='http://www.plantuml.com/plantuml/img/')  # Public server\n",
        "\n",
        "# Generate use case scenarios and corresponding PlantUML sequence diagrams\n",
        "# use_case_results = []\n",
        "plantuml_scripts = []\n",
        "sequence_diagrams = []\n",
        "\n",
        "for idx, story in enumerate(user_stories, start=1):\n",
        "    print(f\"Processing User Story {idx}/{len(user_stories)}\")\n",
        "    # use_case = get_use_case_scenarios_in_uml(story)\n",
        "    # use_case_results.append((story, use_case))\n",
        "\n",
        "    # Generate PlantUML script\n",
        "    plantuml_script = get_plantuml_sequence_diagram(story)\n",
        "    plantuml_scripts.append((story, plantuml_script))\n",
        "\n",
        "    # Save PlantUML script to a file\n",
        "    sanitized_story = \"\".join([c if c.isalnum() or c in (' ', '_') else '_' for c in story])[:50]\n",
        "    puml_filename = f\"{plantuml_dir}/sequence_{idx}_{sanitized_story}.puml\"\n",
        "    with open(puml_filename, 'w') as f:\n",
        "        f.write(plantuml_script)\n",
        "\n",
        "    # Optionally, generate and save the sequence diagram image\n",
        "    try:\n",
        "        # Using PlantUML public server to generate the image\n",
        "        diagram_url = plantuml_server.get_url(plantuml_script)\n",
        "        diagram_filename = f\"{plantuml_dir}/sequence_{idx}_{sanitized_story}.png\"\n",
        "        # Download the image\n",
        "        import requests\n",
        "        img_data = requests.get(diagram_url).content\n",
        "        with open(diagram_filename, 'wb') as img_file:\n",
        "            img_file.write(img_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating diagram for story {idx}: {e}\")\n",
        "\n",
        "    time.sleep(1)  # Add delay to avoid rate limits\n",
        "\n",
        "# Save use case scenarios to a Word document\n",
        "# doc = Document()\n",
        "# doc.add_heading('UML Use Case Scenarios', level=1)\n",
        "\n",
        "# for story, use_case in use_case_results:\n",
        "#     doc.add_heading(f\"User Story: {story}\", level=2)\n",
        "#     doc.add_paragraph(use_case)\n",
        "#     doc.add_paragraph(\"\\n\")  # Add a blank line between entries\n",
        "\n",
        "# doc.save(\"use_case_scenarios.docx\")\n",
        "\n",
        "# Save PlantUML scripts to a separate Word document (optional)\n",
        "puml_doc = Document()\n",
        "puml_doc.add_heading('PlantUML Sequence Diagrams', level=1)\n",
        "\n",
        "for story, script in plantuml_scripts:\n",
        "    puml_doc.add_heading(f\"User Story: {story}\", level=2)\n",
        "    puml_doc.add_paragraph(script)\n",
        "    puml_doc.add_paragraph(\"\\n\")  # Add a blank line between entries\n",
        "\n",
        "puml_doc.save(\"plantuml_sequence_diagrams.docx\")\n",
        "\n",
        "# Notify the user\n",
        "print(\"Word documents saved as 'use_case_scenarios.docx' and 'plantuml_sequence_diagrams.docx'.\")\n",
        "print(f\"PlantUML scripts and sequence diagram images are saved in the '{plantuml_dir}' directory.\")\n",
        "\n",
        "# Download the Word files in Google Colab (if applicable)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    # files.download('use_case_scenarios.docx')\n",
        "    files.download('plantuml_sequence_diagrams.docx')\n",
        "    # Optionally, zip the PlantUML directory and download\n",
        "    import shutil\n",
        "    shutil.make_archive(\"plantuml_sequences\", 'zip', plantuml_dir)\n",
        "    files.download(\"plantuml_sequences.zip\")\n",
        "except ImportError:\n",
        "    print(\"Google Colab is not being used, files saved locally.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "GwS69HgfpaBZ",
        "outputId": "21f3bd22-f084-4e08-8989-bd7a324bf0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_76915fff-7d0f-4380-a1a3-b7a447cfdcb6\", \"plantuml_sequence_diagrams.docx\", 45360)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_541428ed-caa7-47e2-978c-c58e5c48146c\", \"plantuml_sequences.zip\", 627781)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
